{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b05412",
   "metadata": {},
   "source": [
    "Final flow \n",
    "- all code in functions\n",
    "- data pull from geoserver\n",
    "- column descriptions and layer descriptions from csv\n",
    "- style file from github\n",
    "- output stored locally\n",
    "\n",
    "Common functions between raster and vector wherever possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99cb8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rasterio\n",
    "import os\n",
    "# import fsspec\n",
    "# import s3fs\n",
    "\n",
    "# import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime\n",
    "# from datetime import datetime, timezone\n",
    "\n",
    "import urllib\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# from rasterio.warp import transform_bounds\n",
    "\n",
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "from shapely.geometry import mapping, box, Polygon\n",
    "\n",
    "import pystac\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62c348a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install fsspec s3fs\n",
    "# !pip install numpy pandas geopandas matplotlib rasterio shapely pystac boto3 requests tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ee77845",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEOSERVER_BASE_URL = constants.GEOSERVER_BASE_URL\n",
    "# GEOSERVER_BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6304330",
   "metadata": {},
   "outputs": [],
   "source": [
    "THUMBNAIL_DATA_URL = constants.GITHUB_DATA_URL\n",
    "#THUMBNAIL_DATA_URL = constants.S3_STAC_BUCKET_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2cc47232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAC_S3_BUCKET_URL=constants.S3_STAC_BUCKET_URL\n",
    "# STAC_S3_BUCKET_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b58b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_DIR = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca8d0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_FILE_DIR = os.path.join(LOCAL_DATA_DIR,'input/style_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73be265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "THUMBNAIL_DIR = os.path.join(LOCAL_DATA_DIR,\n",
    "                             'generated_change_layers_STAC_output_new')\n",
    "# THUMBNAIL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c01f9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEHSIL_DIRNAME = 'tehsil_wise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c24c9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAC_FILES_DIR = os.path.join(\n",
    "    LOCAL_DATA_DIR,\n",
    "    'CorestackCatalogs_generated_change_layers_STAC_new' #test folder\n",
    ")\n",
    "#'CorestackCatalogs_exception_handling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5eddceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_DESC_GITHUB_URL = constants.LAYER_DESC_GITHUB_URL\n",
    "# LAYER_DESC_GITHUB_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "340b7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_COLUMN_DESC_GITHUB_URL = constants.VECTOR_COLUMN_DESC_GITHUB_URL\n",
    "# VECTOR_COLUMN_DESC_GITHUB_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b123083",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_STAC_BUCKET_NAME = constants.S3_STAC_BUCKET_NAME\n",
    "# S3_STAC_BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19bb31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_STAC_generated = False #output flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c851872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_gee_text(description):\n",
    "    description = re.sub(r\"[^a-zA-Z0-9 .,:;_-]\", \"\", description)\n",
    "    return description.replace(\" \", \"_\") #in the main module can be taken from utilities.gee_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437fd29",
   "metadata": {},
   "source": [
    "###Raster flow is designed using the new URL without reading the geotiff file getting the metadata info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62efd831",
   "metadata": {},
   "source": [
    "### Raster flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53b56083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test URLs for Nalanda Hilsa Afforestation\n",
    "# # THUMBNAIL_URL = \"https://geoserver.core-stack.org:8443/geoserver/change_detection/wms?service=WMS&version=1.1.0&request=GetMap&layers=change_detection:change_nalanda_hilsa_Afforestation&bbox=85.11905626298955,24.970829278783988,85.56318333945823,25.489336860777776&width=180&height=180&srs=EPSG:4326&styles=&format=image/png\"\n",
    "\n",
    "# # DESCRIBE_URL = \"https://geoserver.core-stack.org:8443/geoserver/change_detection/wcs?service=WCS&version=2.0.1&request=DescribeCoverage&coverageId=change_detection:change_nalanda_hilsa_Afforestation\"\n",
    "\n",
    "# # #test url for UP, BALRAPUR Afforestation\n",
    "# THUMBNAIL_URL = \"https://geoserver.core-stack.org:8443/geoserver/change_detection/wms?service=WMS&version=1.1.0&request=GetMap&layers=change_detection:change_balrampur_balrampur_Afforestation&bbox=80.99983152765948%2C25.9998494367429%2C83.00011017080843%2C29.0002224857021&width=180&height=180&srs=EPSG:4326&styles=&format=image/png\"\n",
    "\n",
    "# DESCRIBE_URL = \"https://geoserver.core-stack.org:8443/geoserver/change_detection/wcs?service=WCS&version=2.0.1&request=DescribeCoverage&coverageId=change_detection:change_balrampur_balrampur_Afforestation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b093c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_raster_describe_url(workspace, layer_name, geoserver_base_url):\n",
    "    \n",
    "    describe_url = (\n",
    "        f\"{geoserver_base_url}/{workspace}/wcs?\"\n",
    "        f\"service=WCS&version=2.0.1&request=DescribeCoverage&\"\n",
    "        f\"coverageId={workspace}:{layer_name}\"\n",
    "    )\n",
    "    return describe_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96425968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raster_thumbnail_url(workspace, layer_name, bbox, geoserver_base_url):\n",
    "  \n",
    "    bbox_str = \",\".join(map(str, bbox))\n",
    "    \n",
    "    thumbnail_url = (\n",
    "        f\"{geoserver_base_url}/{workspace}/wms?\"\n",
    "        f\"service=WMS&version=1.1.0&request=GetMap&\"\n",
    "        f\"layers={workspace}:{layer_name}&\"\n",
    "        f\"bbox={bbox_str}&\"\n",
    "        f\"width=300&height=300&srs=EPSG:4326&styles=&format=image/png\"\n",
    "    )\n",
    "    return thumbnail_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "65c6dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_wcs(describe_url):\n",
    "    response = requests.get(describe_url, verify=False)\n",
    "    if response.status_code == 200:\n",
    "        root = ET.fromstring(response.content)\n",
    "        # GeoServer uses these standard namespaces for WCS 2.0.1\n",
    "        ns = {\n",
    "            'gml': 'http://www.opengis.net/gml/3.2', \n",
    "            'wcs': 'http://www.opengis.net/wcs/2.0'\n",
    "        }\n",
    "        \n",
    "        # 1. Fetch Bounding Box (Envelope)\n",
    "        envelope = root.find('.//gml:Envelope', ns)\n",
    "        if envelope is not None:\n",
    "            lower = envelope.find('gml:lowerCorner', ns).text.split()\n",
    "            upper = envelope.find('gml:upperCorner', ns).text.split()\n",
    "            \n",
    "            \n",
    "            bbox = [float(lower[1]), float(lower[0]), float(upper[1]), float(upper[0])]\n",
    "            \n",
    "            footprint = Polygon([\n",
    "                [bbox[0], bbox[1]],\n",
    "                [bbox[0], bbox[3]],\n",
    "                [bbox[2], bbox[3]],\n",
    "                [bbox[2], bbox[1]]\n",
    "            ])\n",
    "\n",
    "            # 2. Fetch Actual Pixel Shape (GridEnvelope)\n",
    "            grid_low = root.find('.//gml:low', ns)\n",
    "            grid_high = root.find('.//gml:high', ns)\n",
    "            \n",
    "            if grid_low is not None and grid_high is not None:\n",
    "                low_coords = grid_low.text.split()\n",
    "                high_coords = grid_high.text.split()\n",
    "                \n",
    "               \n",
    "                actual_width = int(high_coords[0]) - int(low_coords[0]) + 1\n",
    "                actual_height = int(high_coords[1]) - int(low_coords[1]) + 1\n",
    "                shape = [actual_height, actual_width] \n",
    "            else:\n",
    "                shape = [0, 0] \n",
    "\n",
    "            return bbox, mapping(footprint), \"EPSG:4326\", shape\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac19efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_wms_thumbnail(wms_url, output_path):\n",
    "    response = requests.get(wms_url, verify=False)\n",
    "    if response.status_code == 200:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2773b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_layer_description(filepath,\n",
    "                           layer_name,\n",
    "                           overwrite_existing\n",
    "                           ):\n",
    "    if ((os.path.exists(filepath)) and (not overwrite_existing)):\n",
    "        layer_desc_df = pd.read_csv(filepath)\n",
    "    else:\n",
    "        #download and save\n",
    "        print(\"STAC:downloading layer description csv from github\")\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        layer_desc_df = pd.read_csv(LAYER_DESC_GITHUB_URL)\n",
    "        layer_desc_df.to_csv(filepath)\n",
    "    if (layer_name in layer_desc_df['layer_name'].tolist()):\n",
    "        layer_desc = layer_desc_df[layer_desc_df['layer_name'] == layer_name]['layer_description'].iloc[0]\n",
    "    else:\n",
    "        print(f\"layer description for {layer_name} layer does not exist currently\")\n",
    "        layer_desc = ''\n",
    "    return layer_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a3b16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raster_url(workspace,\n",
    "                        layer_name,\n",
    "                        geoserver_base_url,\n",
    "                        output_format=\"geotiff\"):\n",
    "    wcs_url = (\n",
    "        f\"{geoserver_base_url}/{workspace}/wcs?\"\n",
    "        f\"service=WCS&version=2.0.1&request=GetCoverage&\"\n",
    "        f\"CoverageId={workspace}:{layer_name}&\"\n",
    "        f\"format={output_format}&compression=LZW\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(\"Raster URL:\",wcs_url)\n",
    "    return wcs_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11807658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_raster_data(raster_url):\n",
    "\n",
    "#     #when reading from geoserver\n",
    "#     response = requests.get(raster_url, verify=False)\n",
    "\n",
    "#     #exception handling: scenario 1: when fetching data from geoserver\n",
    "#     try:\n",
    "#         response.raise_for_status()\n",
    "#     except Exception as e:\n",
    "#          print(\"STAC_Error: \" + str(e) + \"when fetching geoserver data\")\n",
    "#          print(\"exiting STAC pipeline\")\n",
    "#          return layer_STAC_generated\n",
    "\n",
    "#     raster_data = BytesIO(response.content)\n",
    "\n",
    "#     #read the data and fetch the metadata\n",
    "#     with rasterio.open(raster_data) as r:\n",
    "#         crs = r.crs\n",
    "#         bounds = r.bounds\n",
    "#         bbox = [bounds.left, bounds.bottom, bounds.right, bounds.top]\n",
    "#         footprint = Polygon([\n",
    "#             [bounds.left, bounds.bottom],\n",
    "#             [bounds.left, bounds.top],\n",
    "#             [bounds.right, bounds.top],\n",
    "#             [bounds.right, bounds.bottom]\n",
    "#         ])\n",
    "#         data = r.read(1) #TODO: wouldn't work if there are multiple bands\n",
    "        \n",
    "#         # thumbnail_size = 256  # pixels\n",
    "#         # scale_x = r.width / thumbnail_size\n",
    "#         # scale_y = r.height / thumbnail_size\n",
    "\n",
    "#         # data = r.read(1, out_shape=(1, int(r.height / scale_y), int(r.width / scale_x)))\n",
    "\n",
    "#         # id = os.path.basename(raster_url) #works when data is local\n",
    "#         # id = layer_name\n",
    "#         # gsd = 10\n",
    "#         shape = r.shape\n",
    "#         data_type = str(r.dtypes[0])\n",
    "        \n",
    "#         return (data,\n",
    "#                 bbox,\n",
    "#                 mapping(footprint),\n",
    "#                 crs,\n",
    "#                 # id,\n",
    "#                 # gsd,\n",
    "#                 shape,\n",
    "#                 data_type\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "605c3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raster_item(describe_url,\n",
    "                       id,\n",
    "                       layer_title,\n",
    "                       layer_description,\n",
    "                       display_name,\n",
    "                       theme,\n",
    "                       start_date='',\n",
    "                       end_date='',\n",
    "                       gsd=pd.NA\n",
    "                       ):\n",
    "\n",
    "    \n",
    "    metadata = get_metadata_from_wcs(describe_url)\n",
    "    if metadata is None:\n",
    "        print(f\"STAC_Error: Could not fetch metadata for {id}\")\n",
    "        return None\n",
    "        \n",
    "    bbox, footprint, crs, shape = metadata\n",
    "    keyword = display_name.lower()\n",
    "\n",
    "    if ((start_date != '') & (end_date != '') & (not pd.isna(gsd))):\n",
    "        raster_item = pystac.Item(id=id,\n",
    "                                  geometry=footprint,\n",
    "                                  bbox=bbox,\n",
    "                                  datetime=datetime.datetime.now(datetime.timezone.utc),\n",
    "                                  properties={\n",
    "                                        \"title\" : layer_title,\n",
    "                                        \"description\" : layer_description,\n",
    "                                        \"start_datetime\": start_date.isoformat() + 'Z',\n",
    "                                        \"end_datetime\": end_date.isoformat() + 'Z',\n",
    "                                        \"gsd\": gsd,\n",
    "                                        \"keywords\": [theme]\n",
    "                                  })\n",
    "    elif (not pd.isna(gsd)): \n",
    "         raster_item = pystac.Item(id=id,\n",
    "                                  geometry=footprint,\n",
    "                                  bbox=bbox,\n",
    "                                  datetime=datetime.datetime.now(datetime.timezone.utc),  \n",
    "                                  properties={\n",
    "                                        \"title\" : layer_title,\n",
    "                                        \"description\" : layer_description,\n",
    "                                      \"gsd\": gsd,\n",
    "                                      \"start_datetime\": constants.DEFAULT_START_DATE.strftime('%Y-%m-%dT%H:%M:%SZ'), \n",
    "                                      \"end_datetime\": constants.DEFAULT_END_DATE.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                                      \"keywords\": [theme]                                                 \n",
    "                                  })       \n",
    "    else:\n",
    "         raster_item = pystac.Item(id=id,\n",
    "                                  geometry=footprint,\n",
    "                                  bbox=bbox,\n",
    "                                  datetime=datetime.datetime.now(datetime.timezone.utc),\n",
    "                                  properties={\n",
    "                                        \"title\" : layer_title,\n",
    "                                        \"description\" : layer_description,\n",
    "                                        \"gsd\": gsd,\n",
    "                                        \"start_datetime\": constants.DEFAULT_START_DATE.strftime('%Y-%m-%dT%H:%M:%SZ'), \n",
    "                                        \"end_datetime\": constants.DEFAULT_END_DATE.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                                        \"keywords\": [theme]\n",
    "                                  })            \n",
    "    \n",
    "    \n",
    "    proj_ext = pystac.extensions.projection.ProjectionExtension.ext(raster_item, add_if_missing=True)\n",
    "    proj_ext.epsg = crs\n",
    "    proj_ext.shape = [shape[0], shape[1]]\n",
    "\n",
    "    return raster_item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c797afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_raster_data_asset(raster_item,\n",
    "                          geoserver_url\n",
    "                          ):\n",
    "    raster_item.add_asset(\"data\", pystac.Asset(\n",
    "        # href=os.path.join(data_url, os.path.relpath(raster_path, start=data_dir)), #TODO\n",
    "        href=geoserver_url,\n",
    "        media_type=pystac.MediaType.GEOTIFF,\n",
    "        roles=[\"data\"],\n",
    "        title=\"Raster Layer\"))\n",
    "\n",
    "    return raster_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d88b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_raster_extension(raster_item): #TODO\n",
    "#         #add certain metadata under raster extension\n",
    "#     raster_ext = pystac.extensions.raster.RasterExtension.ext(raster_item.assets[\"data\"], add_if_missing=True)\n",
    "#     raster_band = pystac.extensions.raster.RasterBand.create(\n",
    "#         data_type=data_type, \n",
    "#         spatial_resolution=gsd,\n",
    "#         # nodata=nodata\n",
    "#     )\n",
    "#     raster_ext.bands = [raster_band]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a64dc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raster_style_file(style_file_url,\n",
    "                            STYLE_FILE_DIR\n",
    "                            ):\n",
    "    \n",
    "    #download style file if not already downloaded, and save it locally\n",
    "    style_file_name = os.path.basename(style_file_url)\n",
    "    style_file_local_path = os.path.join(STYLE_FILE_DIR,\n",
    "                                         style_file_name)\n",
    "    \n",
    "    if not os.path.exists(style_file_local_path):\n",
    "            #TODO: try statement\n",
    "            os.makedirs(os.path.dirname(style_file_local_path), exist_ok=True)\n",
    "            try:\n",
    "                urllib.request.urlretrieve(style_file_url,\n",
    "                                           style_file_local_path)  \n",
    "            #exception handling: scenario 2: when fetching style file from github\n",
    "            except Exception as e:\n",
    "                print(\"STAC_Error: Could not retrieve style file from github. Error: \" + str(e))\n",
    "                print(\"exiting STAC pipeline\")\n",
    "                return layer_STAC_generated\n",
    "    \n",
    "    tree = ET.parse(style_file_local_path)\n",
    "    root = tree.getroot()\n",
    "    classes = []\n",
    "\n",
    "    for entry in root.findall(\".//paletteEntry\"):\n",
    "        class_info = {}\n",
    "        for attr_key, attr_value in entry.attrib.items():\n",
    "            if attr_key == \"value\":\n",
    "                try:\n",
    "                    class_info[attr_key] = int(attr_value)\n",
    "                except ValueError:\n",
    "                    class_info[attr_key] = attr_value\n",
    "            else:\n",
    "                class_info[attr_key] = attr_value\n",
    "        classes.append(class_info)\n",
    "\n",
    "    # If no paletteEntry tags are found, check for item tags\n",
    "    if not classes:\n",
    "        for entry in root.findall(\".//item\"):\n",
    "            class_info = {}\n",
    "            for attr_key, attr_value in entry.attrib.items():\n",
    "                if attr_key == \"value\":\n",
    "                    try:\n",
    "                        class_info[attr_key] = int(attr_value)\n",
    "                    except ValueError:\n",
    "                        class_info[attr_key] = attr_value\n",
    "                else:\n",
    "                    class_info[attr_key] = attr_value\n",
    "            classes.append(class_info)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ee2a3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_classification_extension(raster_style_url,\n",
    "                                 raster_item,\n",
    "                                 STYLE_FILE_DIR\n",
    "                                 ):\n",
    "    \n",
    "    style_info = parse_raster_style_file(style_file_url=raster_style_url,\n",
    "                                         STYLE_FILE_DIR=STYLE_FILE_DIR\n",
    "                                         )\n",
    "    classification_ext = pystac.extensions.classification.ClassificationExtension.ext(raster_item.assets[\"data\"], add_if_missing=True)\n",
    "    stac_classes = []\n",
    "    for cls in style_info:\n",
    "        stac_class_obj = pystac.extensions.classification.Classification.create(\n",
    "            value=int(cls[\"value\"]),\n",
    "            name=cls.get(\"label\") or f\"Class {cls['value']}\",\n",
    "            description=cls.get(\"label\"),\n",
    "            color_hint=cls['color'].replace('#','')\n",
    "        )\n",
    "        stac_classes.append(stac_class_obj)\n",
    "    classification_ext.classes = stac_classes\n",
    "\n",
    "    return (raster_item,style_info) #style info is required for thumbnail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6c52c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stylefile_asset(STAC_item,\n",
    "                        style_file_url):\n",
    "    STAC_item.add_asset(\"style\", pystac.Asset(\n",
    "        # href=os.path.join(data_url, os.path.relpath(raster_style_path, start=data_dir)),\n",
    "        href=style_file_url,\n",
    "        media_type=pystac.MediaType.XML,\n",
    "        roles=[\"metadata\"],\n",
    "        title=\"QGIS Style file\"\n",
    "    ))\n",
    "    return STAC_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "732f5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raster_thumbnail(raster_data,\n",
    "                              style_info,\n",
    "                              output_path\n",
    "                              ):\n",
    "    \n",
    "    unique_raster_values = np.unique(raster_data.compressed() if isinstance(raster_data, np.ma.MaskedArray) else raster_data)\n",
    "    # Filter QML info to only include values present in the raster data\n",
    "    filtered_style_info = [cls for cls in style_info if cls.get('value') in unique_raster_values]\n",
    "    \n",
    "    values = [cls['value'] for cls in filtered_style_info if 'value' in cls]\n",
    "    colors = [cls['color'] for cls in filtered_style_info if 'color' in cls]\n",
    "    \n",
    "    # print(f\"Parsed QML values: {values}\")\n",
    "    # print(f\"Parsed QML colors: {colors}\")\n",
    "        \n",
    "    try:\n",
    "        if not values or not colors or len(values) != len(colors):\n",
    "            raise ValueError(\"Invalid or insufficient palette information in QML file.\")\n",
    "    \n",
    "        sorted_indices = np.argsort(values)\n",
    "        sorted_values = np.array(values)[sorted_indices]\n",
    "        sorted_colors = np.array(colors)[sorted_indices]\n",
    "\n",
    "        cmap = ListedColormap(sorted_colors)\n",
    "        bounds = np.array(sorted_values) - 0.5\n",
    "        bounds = np.append(bounds, sorted_values[-1] + 0.5)\n",
    "        norm = Normalize(vmin=bounds.min(), vmax=bounds.max())\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping palette generation due to error: {e}. Using a default colormap.\")\n",
    "        cmap = 'gray'\n",
    "        norm = None\n",
    "    plt.figure(figsize=(3, 3), dpi=100)\n",
    "    \n",
    "    plt.imshow(raster_data, cmap=cmap, norm=norm, interpolation='none')\n",
    "    plt.axis('off')\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7dd6bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_thumbnail_asset(STAC_item,\n",
    "                        THUMBNAIL_PATH,\n",
    "                        LOCAL_DATA_DIR, #TODO\n",
    "                        THUMBNAIL_DATA_URL\n",
    "                        ):\n",
    "    STAC_item.add_asset(\"thumbnail\", pystac.Asset(\n",
    "        href=os.path.join(THUMBNAIL_DATA_URL, os.path.relpath(THUMBNAIL_PATH,\n",
    "                                                           start=LOCAL_DATA_DIR)),\n",
    "        # href=os.path.join(THUMBNAIL_DATA_URL, os.path.relpath(THUMBNAIL_PATH,\n",
    "        #                                                    start=LOCAL_DATA_DIR)),\n",
    "        media_type=pystac.MediaType.PNG,\n",
    "        roles=[\"thumbnail\"],\n",
    "        title=\"Thumbnail\"\n",
    "    ))\n",
    "\n",
    "    return STAC_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3236da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_layer_mapping(layer_map_csv_path, #TODO: update this function for each type of layer\n",
    "                       layer_name,\n",
    "                       district, #\n",
    "                       block,\n",
    "                       start_year = '',\n",
    "                    #    end_year = ''\n",
    "                       ):\n",
    "    layer_mapping_df = pd.read_csv(layer_map_csv_path)\n",
    "    layer_display_name = layer_mapping_df[layer_mapping_df['layer_name'] == layer_name]['display_name'].iloc[0]\n",
    "\n",
    "    geoserver_workspace_name = layer_mapping_df[layer_mapping_df['layer_name'] == layer_name]['geoserver_workspace_name'].iloc[0]\n",
    "    geoserver_layer_name = layer_mapping_df[layer_mapping_df['layer_name'] == layer_name]['geoserver_layer_name'].iloc[0]\n",
    "    \n",
    "    style_file_url = layer_mapping_df[layer_mapping_df['layer_name'] == layer_name]['style_file_url'].iloc[0]\n",
    "    ee_layer_name = layer_mapping_df[layer_mapping_df['layer_name'] == layer_name]['ee_layer_name'].iloc[0]\n",
    "\n",
    "    gsd = layer_mapping_df[layer_mapping_df['layer_name'] == layer_name]['spatial_resolution_in_meters'].iloc[0]\n",
    "    \n",
    "    theme = layer_mapping_df[layer_mapping_df[\"layer_name\"] == layer_name][\n",
    "        \"theme\"\n",
    "    ].iloc[0]\n",
    "\n",
    "    if (layer_name == 'land_use_land_cover_raster'):\n",
    "        start_year_modified = str(\n",
    "            int(start_year) % 100\n",
    "        )  # keep only last 2 digits of the full year\n",
    "        end_year_modified = str((int(start_year) + 1) % 100)\n",
    "        print(\"start_year_modified=\", start_year_modified)\n",
    "        print(\"end_year_modified=\", end_year_modified)\n",
    "        geoserver_layer_name = geoserver_layer_name.format(\n",
    "            start_year=start_year_modified, end_year=end_year_modified, district=district, block=block\n",
    "        )\n",
    "    # prin\n",
    "    # print(geoserver_workspace_name,geoserver_layer_name)\n",
    "    elif ((layer_name == 'tree_canopy_cover_density_raster') |\\\n",
    "          (layer_name == 'tree_canopy_height_raster')):\n",
    "                geoserver_layer_name = geoserver_layer_name.format(start_year = start_year,\n",
    "                                                                   district = district,\n",
    "                                                                   block = block)\n",
    "    else: #only LULC has some specific things such as 2 digit year representation and no district information\n",
    "        geoserver_layer_name = geoserver_layer_name.format(district = district,\n",
    "                                                           block = block)\n",
    "    return (geoserver_workspace_name,\n",
    "            geoserver_layer_name,\n",
    "            style_file_url,\n",
    "            layer_display_name,\n",
    "            ee_layer_name,\n",
    "            gsd,\n",
    "            theme,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "12533997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raster_item(state, district, block, layer_name, layer_map_csv_path, \n",
    "                         layer_desc_csv_path, start_year, overwrite_existing): \n",
    "    \n",
    "    # 1. read layer description\n",
    "    layer_description = read_layer_description(filepath=layer_desc_csv_path,\n",
    "                                             layer_name=layer_name,\n",
    "                                             overwrite_existing=overwrite_existing)\n",
    "    \n",
    "    #2. get geoserver url parameters from the layer details\n",
    "    geoserver_workspace_name, geoserver_layer_name, style_file_url, layer_display_name, ee_layer_name, gsd ,theme = \\\n",
    "        read_layer_mapping(layer_map_csv_path=layer_map_csv_path,\n",
    "                          district=district, block=block, \n",
    "                          layer_name=layer_name, \n",
    "                          start_year=start_year)\n",
    "    \n",
    "    print(f\"geoserver_workspace_name={geoserver_workspace_name}\")\n",
    "    print(f\"geoserver_layer_name={geoserver_layer_name}\")\n",
    "    print(f\"style file url = {style_file_url}\")\n",
    "\n",
    "    # 3.generate describe url\n",
    "    geoserver_url = generate_raster_url(workspace=geoserver_workspace_name,\n",
    "                                       layer_name=geoserver_layer_name,\n",
    "                                       geoserver_base_url=GEOSERVER_BASE_URL)\n",
    "\n",
    "    # 4. create raster item using the describe_url\n",
    "    # updated layer title and layer id\n",
    "    start_date = \"\"\n",
    "    end_date = \"\"\n",
    "    layer_title = layer_display_name  # default layer title\n",
    "    layer_id = f\"{state}_{district}_{block}_{layer_name}\"  # default layer id\n",
    "\n",
    "    # Update it further if start year and end year exist\n",
    "    if start_year != \"\":\n",
    "        layer_title = f\"{layer_display_name} : {start_year}\"\n",
    "        layer_id = f\"{state}_{district}_{block}_{layer_name}_{start_year}\"\n",
    "        start_date = start_year + \"-\" + constants.AGRI_YEAR_START_DATE\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "        end_date = str(int(start_year) + 1) + \"-\" + constants.AGRI_YEAR_END_DATE\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    print(f\"start_date = {start_date}\")\n",
    "    print(f\"end_date = {end_date}\")\n",
    "    \n",
    "    DESCRIBE_URL = generate_raster_describe_url(\n",
    "        workspace=geoserver_workspace_name, \n",
    "        layer_name=geoserver_layer_name, \n",
    "        geoserver_base_url=GEOSERVER_BASE_URL\n",
    "    )\n",
    "    \n",
    "    raster_item = create_raster_item(describe_url=DESCRIBE_URL, \n",
    "                                     id=layer_id,\n",
    "                                     layer_title=layer_title,\n",
    "                                     layer_description=layer_description,\n",
    "                                     display_name=layer_display_name,\n",
    "                                     theme=theme,\n",
    "                                     start_date=start_date,\n",
    "                                     end_date=end_date,\n",
    "                                     gsd=gsd)\n",
    "    \n",
    "    if raster_item is None:\n",
    "        return None\n",
    "\n",
    "    # 5. Add Raster Data Asset\n",
    "    raster_item = add_raster_data_asset(raster_item, geoserver_url=geoserver_url)\n",
    "    \n",
    "    # 6. Add Classification Extension\n",
    "    raster_item, style_info = add_classification_extension(raster_style_url=style_file_url,\n",
    "                                                          raster_item=raster_item,\n",
    "                                                          STYLE_FILE_DIR=STYLE_FILE_DIR)\n",
    "    \n",
    "    # 7. Add Style File Asset\n",
    "    add_stylefile_asset(STAC_item=raster_item, style_file_url=style_file_url)\n",
    "\n",
    "    # 8. GENERATE THUMBNAIL URL \n",
    "    if (start_year != ''):\n",
    "        thumbnail_filename = f'{state}_{district}_{block}_{layer_name}_{start_year}.png'\n",
    "    else:\n",
    "        thumbnail_filename = f'{state}_{district}_{block}_{layer_name}.png' #TODO:\n",
    "    \n",
    "    THUMBNAIL_PATH = os.path.join(THUMBNAIL_DIR, thumbnail_filename)\n",
    "    \n",
    "    \n",
    "    THUMBNAIL_URL = generate_raster_thumbnail_url(\n",
    "        workspace=geoserver_workspace_name,\n",
    "        layer_name=geoserver_layer_name,\n",
    "        bbox=raster_item.bbox,\n",
    "        geoserver_base_url=GEOSERVER_BASE_URL\n",
    "    )\n",
    "\n",
    "    # 9. Download and Add Thumbnail Asset\n",
    "    if download_wms_thumbnail(wms_url=THUMBNAIL_URL, output_path=THUMBNAIL_PATH):\n",
    "        raster_item = add_thumbnail_asset(\n",
    "            STAC_item=raster_item,\n",
    "            THUMBNAIL_PATH=THUMBNAIL_PATH,\n",
    "            LOCAL_DATA_DIR=LOCAL_DATA_DIR,\n",
    "            THUMBNAIL_DATA_URL=THUMBNAIL_DATA_URL\n",
    "        )\n",
    "\n",
    "    return raster_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d52c70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def update_STAC_files(state,\n",
    "                      district,\n",
    "                      block,\n",
    "                      STAC_item):\n",
    "    \n",
    "    # Helper function to merge two bounding boxes: [minx, miny, maxx, maxy]\n",
    "    def merge_bboxes(bbox1, bbox2):\n",
    "        if not bbox1 or bbox1 == [0, 0, 0, 0]:\n",
    "            return bbox2\n",
    "        return [\n",
    "            min(bbox1[0], bbox2[0]),\n",
    "            min(bbox1[1], bbox2[1]),\n",
    "            max(bbox1[2], bbox2[2]),\n",
    "            max(bbox1[3], bbox2[3])\n",
    "        ]\n",
    "\n",
    "    \n",
    "    item_bbox = STAC_item.bbox \n",
    "\n",
    "    # 1. create block collection, if not already existing \n",
    "    block_dir = os.path.join(STAC_FILES_DIR,\n",
    "                             TEHSIL_DIRNAME,\n",
    "                             state,\n",
    "                             district,\n",
    "                             block)\n",
    "    os.makedirs(block_dir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    block_catalog_path = os.path.join(block_dir, 'collection.json')\n",
    "\n",
    "    if os.path.exists(block_catalog_path):\n",
    "        block_catalog = pystac.read_file(block_catalog_path)\n",
    "        print(f\"Loaded existing block collection: {block}\")\n",
    "\n",
    "        \n",
    "        current_bbox = block_catalog.extent.spatial.bboxes[0]\n",
    "        block_catalog.extent.spatial.bboxes = [merge_bboxes(current_bbox, item_bbox)]\n",
    "\n",
    "        block_items = list(block_catalog.get_all_items())\n",
    "        if (STAC_item.id in [x.id for x in block_items]):\n",
    "            block_catalog.remove_item(STAC_item.id)\n",
    "            print(f\"Removed previously existing {STAC_item.id} from the collection\")\n",
    "\n",
    "        block_catalog.add_item(STAC_item)\n",
    "        block_catalog.normalize_and_save(block_dir,\n",
    "                                         catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "        layer_STAC_generated = True\n",
    "        return layer_STAC_generated\n",
    "    else:\n",
    "        \n",
    "        block_catalog = pystac.Collection(\n",
    "            id=block,\n",
    "            title=f\"{block}\",\n",
    "            description=f\"STAC collection for {block} block data in {district}, {state}\",\n",
    "            license=\"CC-BY-4.0\",\n",
    "            extent=pystac.Extent(\n",
    "                spatial=pystac.SpatialExtent([item_bbox]),\n",
    "                temporal=pystac.TemporalExtent([[constants.DEFAULT_START_DATE, \n",
    "                                                 constants.DEFAULT_END_DATE]])),\n",
    "            providers=[ \n",
    "                pystac.Provider(\n",
    "                    name=\"CoRE Stack\",\n",
    "                    roles=[pystac.ProviderRole.PRODUCER, pystac.ProviderRole.PROCESSOR, pystac.ProviderRole.HOST, pystac.ProviderRole.LICENSOR ],\n",
    "                    url=\"https://core-stack.org/\"\n",
    "                    )],\n",
    "            keywords=[\"social-ecological\", \"sustainability\",\"CoRE stack\", block, district, state]                                     \n",
    "        )\n",
    "        print(\"created block collection\")\n",
    "\n",
    "    # 2. add item to block collection\n",
    "    block_catalog.add_item(STAC_item)\n",
    "    \n",
    "    # 3. create district collection if not existing\n",
    "    district_dir = os.path.join(STAC_FILES_DIR,\n",
    "                                TEHSIL_DIRNAME,\n",
    "                                state,\n",
    "                                district)\n",
    "    os.makedirs(district_dir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    district_catalog_path = os.path.join(district_dir, 'collection.json')\n",
    "\n",
    "    if os.path.exists(district_catalog_path):\n",
    "        district_catalog = pystac.read_file(district_catalog_path)\n",
    "        print(\"loaded district collection\")\n",
    "        \n",
    "        \n",
    "        current_bbox = district_catalog.extent.spatial.bboxes[0]\n",
    "        district_catalog.extent.spatial.bboxes = [merge_bboxes(current_bbox, item_bbox)]\n",
    "\n",
    "        district_catalog.add_child(block_catalog)\n",
    "        district_catalog.normalize_and_save(district_dir, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "        layer_STAC_generated = True\n",
    "        return layer_STAC_generated\n",
    "    else: \n",
    "        \n",
    "        district_catalog = pystac.Collection(\n",
    "            id=district,\n",
    "            title=f\"{district}\",\n",
    "            description=f\"STAC collection for data of {district} district\",\n",
    "            license=\"CC-BY-4.0\",\n",
    "            extent=pystac.Extent(\n",
    "                spatial=pystac.SpatialExtent([item_bbox]),\n",
    "                temporal=pystac.TemporalExtent([[constants.DEFAULT_START_DATE, \n",
    "                                                 constants.DEFAULT_END_DATE]])),\n",
    "            providers=[ \n",
    "                pystac.Provider(\n",
    "                    name=\"CoRE Stack\",\n",
    "                    roles=[pystac.ProviderRole.PRODUCER, pystac.ProviderRole.PROCESSOR, pystac.ProviderRole.HOST, pystac.ProviderRole.LICENSOR ],\n",
    "                    url=\"https://core-stack.org/\"\n",
    "                    )],\n",
    "            keywords=[\"social-ecological\", \"sustainability\",\"CoRE stack\", district, state]                                     \n",
    "        )   \n",
    "        print(\"created district collection\")\n",
    "        district_catalog.add_child(block_catalog)\n",
    "        district_catalog.normalize_and_save(district_dir, catalog_type=pystac.CatalogType.SELF_CONTAINED)     \n",
    "\n",
    "    # 4. create state collection if not existing\n",
    "    state_dir = os.path.join(STAC_FILES_DIR,\n",
    "                             TEHSIL_DIRNAME,\n",
    "                             state)\n",
    "    state_collection_path = os.path.join(state_dir, \"collection.json\")\n",
    "\n",
    "    if os.path.exists(state_collection_path):\n",
    "        state_collection = pystac.read_file(state_collection_path)\n",
    "        print(\"loaded state collection\")\n",
    "        \n",
    "        \n",
    "        current_bbox = state_collection.extent.spatial.bboxes[0]\n",
    "        state_collection.extent.spatial.bboxes = [merge_bboxes(current_bbox, item_bbox)]\n",
    "\n",
    "        state_collection.add_child(district_catalog)\n",
    "        state_collection.normalize_and_save(state_dir, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "        layer_STAC_generated = True\n",
    "        return True\n",
    "    else:\n",
    "        state_collection = pystac.Collection(\n",
    "            id=state,\n",
    "            title=state,\n",
    "            description=f\"STAC Collection for data of {state} state.\",\n",
    "            license=\"CC-BY-4.0\",\n",
    "            extent=pystac.Extent(\n",
    "                spatial=pystac.SpatialExtent([item_bbox]), \n",
    "                temporal=pystac.TemporalExtent([[constants.DEFAULT_START_DATE, \n",
    "                                                 constants.DEFAULT_END_DATE]])),\n",
    "            providers=[ \n",
    "                pystac.Provider(\n",
    "                    name=\"CoRE Stack\",\n",
    "                    roles=[pystac.ProviderRole.PRODUCER, pystac.ProviderRole.PROCESSOR, pystac.ProviderRole.HOST, pystac.ProviderRole.LICENSOR ],\n",
    "                    url=\"https://core-stack.org/\"\n",
    "                    )],\n",
    "            keywords=[\"social-ecological\", \"sustainability\",\"CoRE stack\", state]\n",
    "        )\n",
    "          \n",
    "        state_collection.add_link(\n",
    "            pystac.Link(\n",
    "                rel=pystac.RelType.LICENSE,\n",
    "                target=\"https://spdx.org/licenses/CC-BY-4.0.html\",\n",
    "                media_type=\"text/html\")\n",
    "        )\n",
    "         \n",
    "        state_collection.add_link(\n",
    "            pystac.Link(\n",
    "                rel=\"documentation\",\n",
    "                target=\"https://core-stack.org/\",\n",
    "                title=\"CoRE stack\",\n",
    "                media_type=\"application/pdf\")\n",
    "        )\n",
    "\n",
    "        state_collection.add_link(\n",
    "            pystac.Link(\n",
    "                rel=\"documentation\",\n",
    "                target=\"https://drive.google.com/file/d/1ZxovdpPThkN09cB1TcUYSE2BImI7M3k_/view\",\n",
    "                title=\"Technical Manual\",\n",
    "                media_type=\"application/pdf\")\n",
    "        )\n",
    "        \n",
    "        state_collection.add_link(\n",
    "            pystac.Link(\n",
    "                rel=\"documentation\",\n",
    "                target=\"https://github.com/orgs/core-stack-org/repositories\",\n",
    "                title=\"Github link\",\n",
    "                media_type=\"application/pdf\")\n",
    "        ) \n",
    "\n",
    "        print(\"created state collection\")\n",
    "        state_collection.add_child(district_catalog)\n",
    "        state_collection.normalize_and_save(state_dir, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "        \n",
    "    # 5. check if tehsil level catalog exists \n",
    "    tehsil_dir = os.path.join(STAC_FILES_DIR,\n",
    "                              TEHSIL_DIRNAME)\n",
    "    tehsil_catalog_path = os.path.join(tehsil_dir,\"catalog.json\")\n",
    "    if os.path.exists(tehsil_catalog_path):\n",
    "        tehsil_catalog = pystac.read_file(tehsil_catalog_path)\n",
    "        print(\"loaded tehsil catalog\")\n",
    "    else:\n",
    "        tehsil_catalog = pystac.Catalog(\n",
    "            id=TEHSIL_DIRNAME, \n",
    "            title=constants.TEHSIL_CATALOG_TITLE,\n",
    "            description=constants.TEHSIL_CATALOG_DESCRIPTION\n",
    "        )\n",
    "        print(\"created tehsil catalog\")\n",
    "    \n",
    "    if state_collection.id not in [child.id for child in tehsil_catalog.get_children()]:\n",
    "        tehsil_catalog.add_child(state_collection)\n",
    "    tehsil_catalog.normalize_and_save(tehsil_dir, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "\n",
    "    # 6. create root catalog if not existing\n",
    "    root_catalog_path = os.path.join(STAC_FILES_DIR, \"catalog.json\")\n",
    "    if os.path.exists(root_catalog_path):\n",
    "        root_catalog = pystac.read_file(root_catalog_path)\n",
    "        print(\"loaded root catalog\")\n",
    "    else:\n",
    "        root_catalog = pystac.Catalog(\n",
    "            id=\"corestack_STAC\",\n",
    "            title=constants.ROOT_CATALOG_TITLE,\n",
    "            description=constants.ROOT_CATALOG_DESCRIPTION\n",
    "        )\n",
    "        print(\"created root catalog\")\n",
    "\n",
    "    if tehsil_catalog.id not in [child.id for child in root_catalog.get_children()]:    \n",
    "        root_catalog.add_child(tehsil_catalog)\n",
    "  \n",
    "        \n",
    "    root_catalog.normalize_and_save(STAC_FILES_DIR, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n",
    "    layer_STAC_generated = True \n",
    "    return layer_STAC_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30635349",
   "metadata": {},
   "source": [
    "###Vector flow is designed using old URLs only and reads the data for getting the metadata info."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d2811",
   "metadata": {},
   "source": [
    "### Vector flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "72f6ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_url(workspace,\n",
    "                        layer_name,\n",
    "                        geoserver_base_url,\n",
    "                        output_format=\"json\"):\n",
    "    # wfs_url = (\n",
    "    #     f\"{geoserver_base_url}/{workspace}/ows?\"\n",
    "    #     f\"service=WFS&version=1.0.0&request=GetFeature&\"\n",
    "    #     f\"typeName={workspace}:{layer_name}&\"\n",
    "    #     f\"outputFormat==application/json\"\n",
    "    # )\n",
    "\n",
    "    wfs_url = (\n",
    "        f\"{geoserver_base_url}/{workspace}/ows?\"\n",
    "        f\"service=WFS&version=1.0.0&request=GetFeature&\"\n",
    "        f\"typeName={workspace}:{layer_name}&outputFormat=application/json\")\n",
    "    # print(\"Vector URL:\",wfs_url)\n",
    "\n",
    "    return wfs_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75432d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vector_data(vector_url,\n",
    "                     target_crs='4326'\n",
    "                     ):\n",
    "    try:\n",
    "        vector_gdf = gpd.read_file(vector_url)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle specific requests exceptions (e.g., network issues, invalid URL)\n",
    "        print(f\"STAC_Error: Network or URL error: {e} when fetching vector data from geoserver\")\n",
    "        print(\"exiting STAC pipeline\")\n",
    "        return layer_STAC_generated\n",
    "    except Exception as e:\n",
    "        # Handle other general GeoPandas/GDAL-related exceptions (e.g., file format issues)\n",
    "        print(f\"STAC_Error: unexpected error : {e} when fetching vector data from geoserver\")\n",
    "        print(\"exiting STAC pipeline\")\n",
    "        return layer_STAC_generated\n",
    "\n",
    "    vector_gdf = vector_gdf.to_crs(epsg=target_crs)\n",
    "    #TODO: remove such constants like here in crs. make it standard. available in constants. \n",
    "    bounds = vector_gdf.total_bounds\n",
    "    print(bounds)\n",
    "    bbox = [float(b) for b in bounds] #footprint also in vector\n",
    "    print(bbox)\n",
    "    #geometry=box(*bounds).wkt\n",
    "    footprint = Polygon([\n",
    "        [bbox[0], bbox[1]], \n",
    "        [bbox[0], bbox[3]], \n",
    "        [bbox[2], bbox[3]],\n",
    "        [bbox[2], bbox[1]],\n",
    "        [bbox[0], bbox[1]]  \n",
    "    ])\n",
    "\n",
    "    #geom = mapping(vector_gdf.union_all())    \n",
    "    geom=mapping(footprint)\n",
    "    return (vector_gdf,bounds,bbox,geom,footprint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9a1f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_item(vector_url,\n",
    "                       id,\n",
    "                       layer_title,\n",
    "                       layer_description,\n",
    "                       column_desc_csv_path,\n",
    "                       display_name,\n",
    "                       theme,\n",
    "                       ):\n",
    "    try:\n",
    "        vector_gdf, bounds, bbox, footprint , geom = read_vector_data(vector_url=vector_url)\n",
    "    except Exception as e:\n",
    "        print(f\"STAC_Error: {e} when fetching vector data from geoserver\")\n",
    "        print(\"exiting STAC pipeline\")\n",
    "        return layer_STAC_generated\n",
    "    \n",
    "   \n",
    "    start_iso = constants.DEFAULT_START_DATE.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    end_iso = constants.DEFAULT_END_DATE.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    vector_item = pystac.Item(\n",
    "        id=id,\n",
    "        geometry=footprint,\n",
    "        bbox=bbox,\n",
    "        datetime=datetime.datetime.now(datetime.timezone.utc),\n",
    "        properties={\n",
    "            \"title\": layer_title,\n",
    "            \"description\": layer_description,\n",
    "            \"start_datetime\": start_iso,\n",
    "            \"end_datetime\": end_iso,\n",
    "            \"keywords\": [theme]\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    return vector_item,vector_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "338feccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector_data_asset(vector_item,\n",
    "                          geoserver_url\n",
    "                          ):\n",
    "                          \n",
    "    vector_item.add_asset(\"data\", pystac.Asset(\n",
    "        href=geoserver_url,\n",
    "        media_type=pystac.MediaType.GEOJSON,\n",
    "        roles=[\"data\"],\n",
    "        title=\"Vector Layer\"))\n",
    "    \n",
    "    return vector_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bf5e3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tabular_extension(vector_item,\n",
    "                          vector_data_gdf,\n",
    "                          column_desc_csv_path,\n",
    "                          ee_layer_name,\n",
    "                          overwrite_existing=False\n",
    "                          ):\n",
    "    if ((os.path.exists(column_desc_csv_path)) and (not overwrite_existing)):\n",
    "        vector_column_desc_gdf = pd.read_csv(column_desc_csv_path)\n",
    "    else:\n",
    "        print(\"STAC:downloading column descriptions csv from github\")\n",
    "        os.makedirs(os.path.dirname(column_desc_csv_path), exist_ok=True)\n",
    "        vector_column_desc_gdf = pd.read_csv(VECTOR_COLUMN_DESC_GITHUB_URL)\n",
    "        vector_column_desc_gdf.to_csv(column_desc_csv_path)\n",
    "\n",
    "    vector_column_desc_filtered_gdf = vector_column_desc_gdf[vector_column_desc_gdf['ee_layer_name'] == ee_layer_name]\n",
    "    vector_column_desc_filtered_gdf.rename({'column_name_description':'column_description'},axis=1,inplace=True)\n",
    "    table_ext = pystac.extensions.table.TableExtension.ext(vector_item, add_if_missing=True)\n",
    "    vector_merged_df = vector_data_gdf.dtypes.reset_index()\n",
    "    vector_merged_df.columns = ['column_name','column_dtype']\n",
    "    vector_merged_df = vector_merged_df.merge(vector_column_desc_filtered_gdf[['column_name','column_description']],\n",
    "                                            on='column_name',\n",
    "                                            how='left').fillna('')\n",
    "    \n",
    "    table_ext.columns = [\n",
    "        {\n",
    "            \"name\": row['column_name'],\n",
    "            \"type\": str(row['column_dtype']),\n",
    "            \"description\" : row['column_description']\n",
    "        }\n",
    "        for ind,row in vector_merged_df.iterrows()\n",
    "        ]\n",
    "    \n",
    "    return vector_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fba68d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions to generate vector thumbnail \n",
    "def rgba_to_hex(rgba_tuple):\n",
    "    if rgba_tuple is None:\n",
    "        return '#808080'  # Default gray\n",
    "    r, g, b, a = rgba_tuple\n",
    "    return f\"#{int(r*255):02x}{int(g*255):02x}{int(b*255):02x}\"\n",
    "\n",
    "\n",
    "def extract_styling_info(symbol_element):\n",
    "    fill_color = None\n",
    "    outline_color = None\n",
    "    line_width = None\n",
    "\n",
    "    if symbol_element is None:\n",
    "        return fill_color, outline_color, line_width\n",
    "\n",
    "    \n",
    "    fill_layer = symbol_element.find('.//layer[@class=\"SimpleFill\"]')\n",
    "    if fill_layer is not None:\n",
    "        color_option = fill_layer.find('Option[@name=\"color\"]')\n",
    "        if color_option is not None:\n",
    "            try:\n",
    "                rgb_parts = [int(p) for p in color_option.get('value').split(',')[:3]]\n",
    "                fill_color = tuple([p / 255 for p in rgb_parts])\n",
    "            except (ValueError, TypeError):\n",
    "                fill_color = None\n",
    "\n",
    "        outline_option = fill_layer.find('Option[@name=\"outline_color\"]')\n",
    "        if outline_option is not None:\n",
    "            try:\n",
    "                rgb_parts = [int(p) for p in outline_option.get('value').split(',')[:3]]\n",
    "                outline_color = tuple([p / 255 for p in rgb_parts])\n",
    "            except (ValueError, TypeError):\n",
    "                outline_color = None\n",
    "        \n",
    "        width_option = fill_layer.find('Option[@name=\"outline_width\"]')\n",
    "        if width_option is not None:\n",
    "            try:\n",
    "                line_width = float(width_option.get('value'))\n",
    "            except (ValueError, TypeError):\n",
    "                line_width = None\n",
    "\n",
    "    \n",
    "    line_layer = symbol_element.find('.//layer[@class=\"SimpleLine\"]')\n",
    "    if line_layer is not None:\n",
    "        color_option = line_layer.find('Option[@name=\"line_color\"]')\n",
    "        if color_option is not None:\n",
    "            try:\n",
    "                rgb_parts = [int(p) for p in color_option.get('value').split(',')[:3]]\n",
    "                outline_color = tuple([p / 255 for p in rgb_parts])\n",
    "            except (ValueError, TypeError):\n",
    "                outline_color = None\n",
    "        \n",
    "        width_option = line_layer.find('Option[@name=\"line_width\"]')\n",
    "        if width_option is not None:\n",
    "            try:\n",
    "                line_width = float(width_option.get('value'))\n",
    "            except (ValueError, TypeError):\n",
    "                line_width = None\n",
    "    \n",
    "    return fill_color, outline_color, line_width\n",
    "\n",
    "def parse_vector_style_file(style_file_url,\n",
    "                            STYLE_FILE_DIR\n",
    "                            ):\n",
    "    #download style file if not already downloaded, and save it locally\n",
    "    style_file_name = os.path.basename(style_file_url)\n",
    "    style_file_local_path = os.path.join(STYLE_FILE_DIR,\n",
    "                                         style_file_name)\n",
    "    \n",
    "    if not os.path.exists(style_file_local_path):\n",
    "            #TODO: try statement\n",
    "            os.makedirs(os.path.dirname(style_file_local_path), exist_ok=True)\n",
    "            try:\n",
    "                urllib.request.urlretrieve(style_file_url,\n",
    "                                           style_file_local_path)\n",
    "            except Exception as e:\n",
    "                print(\"Could not retrieve style file from url. Error: \" + str(e))\n",
    "    \n",
    "    try:\n",
    "        tree = ET.parse(style_file_local_path)\n",
    "        root = tree.getroot()\n",
    "        renderer_element = root.find('.//renderer-v2')\n",
    "\n",
    "        if renderer_element is None:\n",
    "            print(\"No renderer-v2 element found.\")\n",
    "            return None\n",
    "\n",
    "        renderer_type = renderer_element.get('type')\n",
    "        style = {'renderer_type': renderer_type}\n",
    "        symbols = {s.get('name'): s for s in root.findall('.//symbols/symbol')}\n",
    "\n",
    "        if renderer_type == 'singleSymbol':\n",
    "            symbol_element = renderer_element.find('.//symbol') or symbols.get(renderer_element.get('symbol'))\n",
    "            if symbol_element is not None:\n",
    "                \n",
    "                color_option = symbol_element.find('.//layer/Option[@name=\"line_color\"]') or symbol_element.find('.//layer/Option[@name=\"color\"]')\n",
    "                \n",
    "                if color_option is not None:\n",
    "                    color_value = color_option.get('value').split(',')[0:3]\n",
    "                    rgb_parts = [int(p) for p in color_value]\n",
    "                    style['color'] = (rgb_parts[0] / 255, rgb_parts[1] / 255, rgb_parts[2] / 255)\n",
    "                else:\n",
    "                    \n",
    "                    color_prop = symbol_element.find('.//prop[@k=\"color\"]')\n",
    "                    if color_prop is not None:\n",
    "                        rgb_parts = [int(p) for p in color_prop.get('v').split(',')[:3]]\n",
    "                        style['color'] = (rgb_parts[0] / 255, rgb_parts[1] / 255, rgb_parts[2] / 255)\n",
    "                    else:\n",
    "                        print(f\"Warning: Single symbol color not found in {style_file_local_path}.\")\n",
    "                        return None\n",
    "            else:\n",
    "                print(f\"Warning: Could not find symbol element for singleSymbol in {style_file_local_path}.\")\n",
    "                return None\n",
    "\n",
    "        elif renderer_type == 'categorizedSymbol':\n",
    "            style['attribute'] = renderer_element.get('attr')\n",
    "            style['categories'] = []\n",
    "            for cat in renderer_element.findall('categories/category'):\n",
    "                symbol_element = cat.find('symbol') or symbols.get(cat.get('symbol'))\n",
    "                fill_color, outline_color, line_width = extract_styling_info(symbol_element)\n",
    "                style['categories'].append({\n",
    "                    'value': cat.get('value'),\n",
    "                    'label': cat.get('label'),\n",
    "                    'fill_color': fill_color,\n",
    "                    'outline_color': outline_color,\n",
    "                    'line_width': line_width\n",
    "                })        \n",
    "\n",
    "        elif renderer_type == 'graduatedSymbol':\n",
    "            style['attribute'] = renderer_element.get('attr')\n",
    "            style['classes'] = []\n",
    "            for cls in renderer_element.findall('classes/class'):\n",
    "                symbol_element = cls.find('symbol') or symbols.get(cls.get('symbol'))\n",
    "                fill_color, outline_color, line_width = extract_styling_info(symbol_element)\n",
    "                style['classes'].append({\n",
    "                    'lower_bound': float(cls.get('lower')),\n",
    "                    'upper_bound': float(cls.get('upper')),\n",
    "                    'label': cls.get('label'),\n",
    "                    'fill_color': fill_color,\n",
    "                    'outline_color': outline_color,\n",
    "                    'line_width': line_width\n",
    "                })\n",
    "        \n",
    "        elif renderer_type == 'RuleRenderer':\n",
    "            style['rules'] = []\n",
    "            for rule in renderer_element.findall('.//rule'):\n",
    "                symbol_element = rule.find('.//symbol')\n",
    "                fill_color, outline_color, line_width = extract_styling_info(symbol_element)\n",
    "                style['rules'].append({\n",
    "                    'filter': rule.get('filter'),\n",
    "                    'label': rule.get('label'),\n",
    "                    'fill_color': fill_color,\n",
    "                    'outline_color': outline_color,\n",
    "                    'line_width': line_width\n",
    "                })\n",
    "        else:\n",
    "            print(f\"Warning: Unsupported renderer type '{renderer_type}'. Using default style.\")\n",
    "            return None\n",
    "        return style\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing QML file {style_file_local_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "057f9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_thumbnail(vector_gdf,\n",
    "                              style_file_url,\n",
    "                              output_path,\n",
    "                              STYLE_FILE_DIR\n",
    "                              ):\n",
    "    \n",
    "    try:\n",
    "        # vector_gdf = gpd.read_file(vector_path)\n",
    "        vector_gdf = vector_gdf[vector_gdf.geometry.type.isin(['Polygon', 'MultiPolygon', 'Point', 'LineString'])]\n",
    "        \n",
    "        vector_gdf = vector_gdf[vector_gdf.geometry.notnull() & ~vector_gdf.geometry.is_empty]\n",
    "        vector_gdf = vector_gdf.reset_index(drop=True)\n",
    "        \n",
    "        if vector_gdf.empty:\n",
    "            print(\"No valid polygon data remaining after filtering.\")\n",
    "            return\n",
    "        \n",
    "        style_info = parse_vector_style_file(style_file_url,STYLE_FILE_DIR)\n",
    "\n",
    "\n",
    "        print(\"style_info=\",style_info) #TODO: temporary debug print\n",
    "        fig, ax = plt.subplots(figsize=(3, 3))\n",
    "        \n",
    "        default_fill_color = (0.8, 0.8, 0.8, 1.0) # Light gray\n",
    "        default_outline_color = (0, 0, 0, 1.0)   # Black\n",
    "        default_line_width = 1.0\n",
    "\n",
    "        if style_info is None:\n",
    "            print(\"Applying default style due to parsing error.\")\n",
    "            vector_gdf.plot(ax=ax,\n",
    "                            color=rgba_to_hex(default_fill_color), \n",
    "                            edgecolor=rgba_to_hex(default_outline_color),\n",
    "                            linewidth=default_line_width)\n",
    "        \n",
    "        elif style_info.get('renderer_type') == 'singleSymbol':\n",
    "            print(\"Applying single symbol style...\")\n",
    "            fill_color = style_info.get('fill_color', default_fill_color)\n",
    "            outline_color = style_info.get('outline_color', default_outline_color)\n",
    "            line_width = style_info.get('line_width', default_line_width)\n",
    "            vector_gdf.plot(ax=ax,\n",
    "                            color=rgba_to_hex(fill_color),\n",
    "                            edgecolor=rgba_to_hex(outline_color),\n",
    "                            linewidth=line_width)\n",
    "\n",
    "        elif style_info.get('renderer_type') == 'categorizedSymbol':\n",
    "            print(\"Applying categorized style...\")\n",
    "            \n",
    "            color_map = {\n",
    "                cat.get('value'): rgba_to_hex(cat.get('fill_color' or default_fill_color))\n",
    "                for cat in style_info.get('categories', [])\n",
    "            }\n",
    "            \n",
    "            outline_color_map = {\n",
    "                cat.get('value'): rgba_to_hex(cat.get('outline_color' or default_outline_color))\n",
    "                for cat in style_info.get('categories', [])\n",
    "            }\n",
    "\n",
    "            attribute_name = style_info.get('attribute')\n",
    "            print(\"attribute_name = \",attribute_name) #TODO: temporary debug print\n",
    "\n",
    "            if attribute_name not in vector_gdf.columns:\n",
    "                print(f\"Error: Attribute column '{attribute_name}' not found. Applying default style.\")\n",
    "                vector_gdf.plot(ax=ax,\n",
    "                                color=rgba_to_hex(default_fill_color),\n",
    "                                edgecolor=rgba_to_hex(default_outline_color),\n",
    "                                linewidth=default_line_width)\n",
    "            else:\n",
    "                vector_gdf['mapped_value'] = vector_gdf[attribute_name].apply(lambda x: str(x).strip() if pd.notnull(x) else None)\n",
    "                \n",
    "                fill_colors = vector_gdf['mapped_value'].map(color_map)\n",
    "                fill_colors = fill_colors.fillna(rgba_to_hex(default_fill_color))\n",
    "\n",
    "                outline_colors = vector_gdf['mapped_value'].map(outline_color_map)\n",
    "                outline_colors = outline_colors.fillna(rgba_to_hex(default_outline_color))\n",
    "\n",
    "                print(\"fill_colors=\",fill_colors) #TODO : debug print\n",
    "                \n",
    "                vector_gdf.plot(ax=ax, color=fill_colors, edgecolor=outline_colors, linewidth=default_line_width)\n",
    "\n",
    "            \n",
    "\n",
    "        elif style_info.get('renderer_type') == 'graduatedSymbol':\n",
    "            print(\"Applying graduated style...\")\n",
    "            attribute_name = style_info.get('attribute')\n",
    "            if attribute_name not in vector_gdf.columns:\n",
    "                print(f\"Error: Attribute column '{attribute_name}' not found. Applying default style.\")\n",
    "                vector_gdf.plot(ax=ax,\n",
    "                                color=rgba_to_hex(default_fill_color),\n",
    "                                edgecolor=rgba_to_hex(default_outline_color),\n",
    "                                linewidth=default_line_width)\n",
    "            else:\n",
    "                fill_colors = []\n",
    "                for _, row in vector_gdf.iterrows():\n",
    "                    val = row[attribute_name]\n",
    "                    found_color = default_fill_color\n",
    "                    for cls in style_info.get('classes', []):\n",
    "                        if cls.get('lower_bound') is not None and cls.get('upper_bound') is not None:\n",
    "                            if cls['lower_bound'] <= val < cls['upper_bound']:\n",
    "                                found_color = cls.get('fill_color', default_fill_color)\n",
    "                                break\n",
    "                    fill_colors.append(rgba_to_hex(found_color))\n",
    "                \n",
    "                vector_gdf.plot(ax=ax,\n",
    "                                color=fill_colors,\n",
    "                                edgecolor=rgba_to_hex(default_outline_color),\n",
    "                                linewidth=default_line_width)\n",
    "\n",
    "        elif style_info.get('renderer_type') == 'RuleRenderer':\n",
    "            print(\"Applying rule-based style...\")\n",
    "            fill_colors = []\n",
    "            for _, row in vector_gdf.iterrows():\n",
    "                assigned_color = default_fill_color\n",
    "                for rule in style_info.get('rules', []):\n",
    "                    try:\n",
    "                        attribute_name = rule['filter'].split(' ')[0].strip().strip('\"').strip(\"'\")\n",
    "                        if attribute_name in row and pd.eval(rule['filter'], local_dict={attribute_name: row[attribute_name]}):\n",
    "                            assigned_color = rule.get('fill_color', default_fill_color)\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        continue \n",
    "                fill_colors.append(rgba_to_hex(assigned_color))\n",
    "\n",
    "            vector_gdf.plot(ax=ax,\n",
    "                            color=fill_colors,\n",
    "                            edgecolor=rgba_to_hex(default_outline_color),\n",
    "                            linewidth=default_line_width)\n",
    "\n",
    "        else:\n",
    "            print(\"Applying default blue style.\")\n",
    "            vector_gdf.plot(ax=ax,\n",
    "                            color='lightblue',\n",
    "                            edgecolor=rgba_to_hex(default_outline_color),\n",
    "                            linewidth=default_line_width)\n",
    "\n",
    "        ax.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close(fig)\n",
    "        print(f\"Thumbnail saved to: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating vector thumbnail: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "577507d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_item(state,\n",
    "                         district,\n",
    "                         block,\n",
    "                         layer_name,\n",
    "                         layer_map_csv_path,\n",
    "                         layer_desc_csv_path,\n",
    "                         column_desc_csv_path,\n",
    "                         overwrite_existing\n",
    "                         ):    \n",
    "    # print(layer_map_csv_path)\n",
    "    # print(layer_desc_csv_path)\n",
    "    # print(column_desc_csv_path)\n",
    "    #1. read layer description\n",
    "    layer_description = read_layer_description(filepath=layer_desc_csv_path,\n",
    "                                               layer_name=layer_name,\n",
    "                                               overwrite_existing=overwrite_existing\n",
    "                                               )\n",
    "    \n",
    "    #2. get geoserver url parameters from the layer details\n",
    "    geoserver_workspace_name,geoserver_layer_name,style_file_url,layer_display_name,ee_layer_name,gsd,theme = \\\n",
    "        read_layer_mapping(layer_map_csv_path = layer_map_csv_path,\n",
    "                           district = district,\n",
    "                           block=block,\n",
    "                           layer_name=layer_name,\n",
    "                        #    start_year=start_year,\n",
    "                        #    end_year=end_year\n",
    "                           )\n",
    "    \n",
    "    # print(f\"geoserver_workspace_name={geoserver_workspace_name}\")\n",
    "    # print(f\"geoserver_layer_name={geoserver_layer_name}\")\n",
    "    # print(f\"style file url = {style_file_url}\")\n",
    "\n",
    "    #3. generate geoserver url\n",
    "    geoserver_url = generate_vector_url(workspace=geoserver_workspace_name,\n",
    "                                        layer_name=geoserver_layer_name,\n",
    "                                        geoserver_base_url=GEOSERVER_BASE_URL)\n",
    "    # print(f\"geoserver url={geoserver_url}\")\n",
    "    \n",
    "    #4. create vector item\n",
    "    layer_title = layer_display_name\n",
    "    layer_id = f\"{state}_{district}_{block}_{layer_name}\"\n",
    "\n",
    "    vector_item,vector_data_gdf = create_vector_item(geoserver_url,                                                     \n",
    "                                                #  id=f\"{layer_name}_{block}\",\n",
    "                                                #  id=geoserver_layer_name,\n",
    "                                                    id=layer_id,\n",
    "                                                    layer_title=layer_title,\n",
    "                                                    layer_description = layer_description,\n",
    "                                                    column_desc_csv_path = column_desc_csv_path,\n",
    "                                                    display_name=layer_display_name,\n",
    "                                                    theme=theme\n",
    "                                                    )\n",
    "    \n",
    "    #5. add vector data asset\n",
    "    vector_item = add_vector_data_asset(vector_item,\n",
    "                                        geoserver_url=geoserver_url)\n",
    "    \n",
    "    #6. add table extension\n",
    "    vector_item = add_tabular_extension(vector_item=vector_item,\n",
    "                                        vector_data_gdf=vector_data_gdf,\n",
    "                                        column_desc_csv_path=column_desc_csv_path,\n",
    "                                        ee_layer_name=ee_layer_name,\n",
    "                                        overwrite_existing=overwrite_existing\n",
    "                                        )\n",
    "    \n",
    "    #7. add style file asset\n",
    "    add_stylefile_asset(STAC_item=vector_item,\n",
    "                        style_file_url=style_file_url\n",
    "                        )\n",
    "    \n",
    "    #start from here : TODO\n",
    "    #8. generate thumbnail\n",
    "    # if (start_year != ''):\n",
    "    #     thumbnail_filename = f'{block}_{layer_name}_{start_year}.png'\n",
    "    # else:\n",
    "    thumbnail_filename = f'{state}_{district}_{block}_{layer_name}.png' #TODO:\n",
    "    THUMBNAIL_PATH = os.path.join(THUMBNAIL_DIR,\n",
    "                                  thumbnail_filename)\n",
    "    \n",
    "    generate_vector_thumbnail(vector_gdf=vector_data_gdf,\n",
    "                              style_file_url=style_file_url,\n",
    "                              output_path=THUMBNAIL_PATH,\n",
    "                              STYLE_FILE_DIR=STYLE_FILE_DIR\n",
    "                              )\n",
    "    \n",
    "    #9. add thumbnail asset\n",
    "    vector_item = add_thumbnail_asset(\n",
    "        STAC_item=vector_item,\n",
    "        THUMBNAIL_PATH=THUMBNAIL_PATH,\n",
    "        LOCAL_DATA_DIR=LOCAL_DATA_DIR,\n",
    "        THUMBNAIL_DATA_URL=THUMBNAIL_DATA_URL\n",
    "    )\n",
    "\n",
    "    return vector_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbefaf",
   "metadata": {},
   "source": [
    "Upload folders to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e0ba7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aws_client(\n",
    "    service_name:str,\n",
    "    aws_access_key_id:str,\n",
    "    aws_secret_access_key:str,\n",
    "    region_name:str='ap-south-1',\n",
    "    aws_session_token=None,\n",
    "):\n",
    "    return boto3.client(\n",
    "        service_name=service_name,\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=region_name,\n",
    "        aws_session_token=aws_session_token,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1eb0a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_CREDS_FILEPATH = constants.AWS_CREDS_FILEPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4ac397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(AWS_CREDS_FILEPATH) as src:\n",
    "#     aws_creds = json.load(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "953a2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_s3(\n",
    "    aws_creds,\n",
    "    filepath,\n",
    "    s3_bucket,\n",
    "    s3_prefix,\n",
    "):\n",
    "    if s3_bucket is None :\n",
    "        raise Exception(\n",
    "            \"'s3_folderpath'\" + \\\n",
    "            \"should be non None.\"\n",
    "        )\n",
    "  \n",
    "    s3_client = create_aws_client(\n",
    "        service_name='s3',\n",
    "        aws_access_key_id=aws_creds['aws_access_key_id'],\n",
    "        aws_secret_access_key=aws_creds['aws_secret_access_key'],\n",
    "        region_name='ap-south-1',\n",
    "        # aws_session_token=aws_creds.aws_session_token,\n",
    "    )\n",
    "\n",
    "    # print('---------------------')\n",
    "    # print('File set to upload:')\n",
    "    # print('---------------------')\n",
    "    # print('filepath :', filepath)\n",
    "    # print('bucket   :', s3_bucket)\n",
    "    # print('prefix   :', s3_prefix)\n",
    "    # print('---------------------')\n",
    "\n",
    "    s3_client.upload_file(\n",
    "        filepath,\n",
    "        s3_bucket,\n",
    "        s3_prefix,\n",
    "        ExtraArgs={'ACL': 'bucket-owner-full-control'},\n",
    "    )\n",
    "\n",
    "    return (s3_bucket,s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "677998ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files_in_folder(folderpath:str):\n",
    "    # https://stackoverflow.com/questions/18394147/how-to-do-a-recursive-sub-folder-search-and-return-files-in-a-list\n",
    "    return [y for x in os.walk(folderpath) for y in glob.glob(os.path.join(x[0], '*')) if os.path.isfile(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3fc04b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_folder_to_s3(\n",
    "    aws_creds,\n",
    "    folderpath,\n",
    "    s3_bucket\n",
    "):\n",
    "    filepaths = get_all_files_in_folder(folderpath=folderpath)\n",
    "    for filepath in tqdm.tqdm(filepaths):\n",
    "        s3_prefix = filepath.split('data/')[1]\n",
    "        upload_file_to_s3(\n",
    "            aws_creds=aws_creds,\n",
    "            filepath=filepath,\n",
    "            s3_bucket=s3_bucket,\n",
    "            s3_prefix=s3_prefix\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b9c0c",
   "metadata": {},
   "source": [
    "Making a combined function to generate raster/vector STAC : \n",
    "The function generates the item, and updates the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d418c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_stac(state,\n",
    "                         district,\n",
    "                         block,\n",
    "                         layer_name,\n",
    "                         layer_map_csv_path='../data/input/metadata/layer_mapping.csv',\n",
    "                         layer_desc_csv_path='../data/input/metadata/layer_descriptions.csv',\n",
    "                         column_desc_csv_path='../data/input/metadata/vector_column_descriptions.csv',\n",
    "                         upload_to_s3=False,\n",
    "                         overwrite_existing=False\n",
    "                         ):\n",
    "    # print(layer_map_csv_path)\n",
    "    state = valid_gee_text(state.lower())\n",
    "    district = valid_gee_text(district.lower())\n",
    "    block = valid_gee_text(block.lower())\n",
    "    \n",
    "    # print(\"state=\",state)\n",
    "    # print(\"district=\",district)\n",
    "    # print(\"block=\",block)\n",
    "\n",
    "    vector_item = generate_vector_item(state,\n",
    "                                        district,\n",
    "                                        block,\n",
    "                                        layer_name,\n",
    "                                        layer_map_csv_path,\n",
    "                                        layer_desc_csv_path,\n",
    "                                        column_desc_csv_path,\n",
    "                                        overwrite_existing\n",
    "                                        )\n",
    "\n",
    "    layer_STAC_generated = update_STAC_files(state,\n",
    "                                             district,\n",
    "                                             block,\n",
    "                                             STAC_item=vector_item)\n",
    "    \n",
    "    if (upload_to_s3):\n",
    "        upload_folder_to_s3(\n",
    "        aws_creds=aws_creds,\n",
    "        folderpath=STAC_FILES_DIR,\n",
    "        s3_bucket=S3_STAC_BUCKET_NAME)\n",
    "\n",
    "        upload_folder_to_s3(\n",
    "        aws_creds=aws_creds,\n",
    "        folderpath=THUMBNAIL_DIR,\n",
    "        s3_bucket=S3_STAC_BUCKET_NAME)\n",
    "    \n",
    "    return layer_STAC_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e61332f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raster_stac(state,\n",
    "                         district,\n",
    "                         block,\n",
    "                         layer_name,\n",
    "                         layer_map_csv_path='../data/input/metadata/layer_mapping.csv',\n",
    "                         layer_desc_csv_path='../data/input/metadata/layer_descriptions.csv',\n",
    "                         start_year='',\n",
    "                        #  end_year='',\n",
    "                         upload_to_s3=False,\n",
    "                         overwrite_existing=False\n",
    "                         ):\n",
    "    state = valid_gee_text(state.lower())\n",
    "    district = valid_gee_text(district.lower())\n",
    "    block = valid_gee_text(block.lower())\n",
    "\n",
    "    # print(\"state=\",state)\n",
    "    # print(\"district=\",district)\n",
    "    # print(\"block=\",block)\n",
    "    \n",
    "    raster_item = generate_raster_item(state,\n",
    "                                       district,\n",
    "                                       block,\n",
    "                                       layer_name,\n",
    "                                       layer_map_csv_path,\n",
    "                                       layer_desc_csv_path,\n",
    "                                       start_year,\n",
    "                                    #    end_year,\n",
    "                                       overwrite_existing\n",
    "                                       )\n",
    "    \n",
    "    layer_STAC_generated = update_STAC_files(state,\n",
    "                                             district,\n",
    "                                             block,\n",
    "                                             STAC_item=raster_item)\n",
    "    \n",
    "    if (upload_to_s3):\n",
    "        upload_folder_to_s3(\n",
    "        aws_creds=aws_creds,\n",
    "        folderpath=STAC_FILES_DIR,\n",
    "        s3_bucket=S3_STAC_BUCKET_NAME)\n",
    "\n",
    "        upload_folder_to_s3(\n",
    "        aws_creds=aws_creds,\n",
    "        folderpath=THUMBNAIL_DIR,\n",
    "        s3_bucket=S3_STAC_BUCKET_NAME)\n",
    "        \n",
    "    return layer_STAC_generated   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e9b87",
   "metadata": {},
   "source": [
    "Test the raster and vector flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de17af36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>district</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gobindpur</td>\n",
       "      <td>saraikela-kharsawan</td>\n",
       "      <td>jharkhand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mirzapur</td>\n",
       "      <td>mirzapur</td>\n",
       "      <td>uttar_pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>koraput</td>\n",
       "      <td>koraput</td>\n",
       "      <td>odisha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badlapur</td>\n",
       "      <td>jaunpur</td>\n",
       "      <td>uttar_pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hilsa</td>\n",
       "      <td>nalanda</td>\n",
       "      <td>bihar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>masalia</td>\n",
       "      <td>dumka</td>\n",
       "      <td>jharkhand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       block             district          state\n",
       "0  gobindpur  saraikela-kharsawan      jharkhand\n",
       "1   mirzapur             mirzapur  uttar_pradesh\n",
       "2    koraput              koraput         odisha\n",
       "3   badlapur              jaunpur  uttar_pradesh\n",
       "4      hilsa              nalanda          bihar\n",
       "5    masalia                dumka      jharkhand"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# block_district_state_df = pd.DataFrame({\n",
    "#     'block' : ['gobindpur','mirzapur','koraput','badlapur','hilsa','masalia'],\n",
    "#     'district' : ['saraikela-kharsawan','mirzapur','koraput','jaunpur','nalanda','dumka'],\n",
    "#     'state' : ['jharkhand','uttar_pradesh','odisha','uttar_pradesh','bihar','jharkhand']\n",
    "# })\n",
    "\n",
    "# block_district_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d2f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jharkhand dumka masalia\n"
     ]
    }
   ],
   "source": [
    "# block = 'masalia'\n",
    "# district = block_district_state_df[block_district_state_df['block'] == block]['district'].iloc[0]\n",
    "# state = block_district_state_df[block_district_state_df['block'] == block]['state'].iloc[0]\n",
    "# print(state,district,block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f2e2b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block = 'kharsawan'\n",
    "# state = 'jharkhand'\n",
    "# district = 'saraikela-kharsawan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3262c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "block='Hilsa'\n",
    "state='Bihar'\n",
    "district='Nalanda'\n",
    "\n",
    "# block='Balrampur'\n",
    "# state='Uttar Pradesh'\n",
    "# district='Balrampur'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46d5cc",
   "metadata": {},
   "source": [
    "<!-- Aquifer: \n",
    "\n",
    "1. Style file has issue : fill color against the categorized column name is none. \n",
    "\n",
    "2. Some data layers are different than others : 2 data layers instead of 1 (masalia vs others (e.g. koraput))  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce2312",
   "metadata": {},
   "source": [
    "Raster URL : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f34a727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block = 'badlapur'\n",
    "# district = block_district_state_df[block_district_state_df['block'] == block]['district'].iloc[0]\n",
    "# state = block_district_state_df[block_district_state_df['block'] == block]['state'].iloc[0]\n",
    "# print(state,district,block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae61717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state='Gujarat'\n",
    "# district='ahmadabad'\n",
    "# block='ahmadabad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4943444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAC:downloading layer description csv from github\n",
      "[85.15560792 25.0103367  85.52521    25.43052615]\n",
      "[85.15560792, 25.0103367, 85.52521, 25.43052615]\n",
      "STAC:downloading column descriptions csv from github\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15775/3973545940.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vector_column_desc_filtered_gdf.rename({'column_name_description':'column_description'},axis=1,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "style_info= {'renderer_type': 'categorizedSymbol', 'attribute': 'WorkCatego', 'categories': [{'value': 'Agri Impact - HH,  Community', 'label': 'Land restoration', 'fill_color': None, 'outline_color': None, 'line_width': None}, {'value': 'Household Livelihood', 'label': 'Off-farm livelihood assets', 'fill_color': None, 'outline_color': None, 'line_width': None}, {'value': 'Irrigation - Site level impact', 'label': 'Irrigation on farms', 'fill_color': None, 'outline_color': None, 'line_width': None}, {'value': 'Others - HH, Community', 'label': 'Community assets', 'fill_color': None, 'outline_color': None, 'line_width': None}, {'value': 'Plantation', 'label': 'Plantations', 'fill_color': None, 'outline_color': None, 'line_width': None}, {'value': 'SWC - Landscape level impact', 'label': 'Soil and Water conservation', 'fill_color': None, 'outline_color': None, 'line_width': None}, {'value': 'Un Identified', 'label': 'Unidentified', 'fill_color': None, 'outline_color': None, 'line_width': None}]}\n",
      "Applying categorized style...\n",
      "attribute_name =  WorkCatego\n",
      "fill_colors= 0        #808080\n",
      "1        #808080\n",
      "2        #808080\n",
      "3        #808080\n",
      "4        #808080\n",
      "          ...   \n",
      "13581    #808080\n",
      "13582    #808080\n",
      "13583    #808080\n",
      "13584    #808080\n",
      "13585    #808080\n",
      "Name: mapped_value, Length: 13586, dtype: object\n",
      "Thumbnail saved to: ../data/generated_change_layers_STAC_output_new/bihar_nalanda_hilsa_nrega_vector.png\n",
      "Loaded existing block collection: hilsa\n",
      "Removed previously existing bihar_nalanda_hilsa_nrega_vector from the collection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_vector_stac(state=state,\n",
    "                     district=district,\n",
    "                     block=block,\n",
    "                     layer_name='nrega_vector',\n",
    "                     upload_to_s3=False,\n",
    "                     overwrite_existing=True\n",
    "                    #  layer_map_csv_path='../data/input/metadata/layer_mapping.csv',\n",
    "                    #  layer_desc_csv_path='../data/input/metadata/layer_descriptions.csv',\n",
    "                    #  column_desc_csv_path='../data/input/metadata/vector_column_descriptions.csv'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e338fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_raster_stac(state=state,\n",
    "#                      district=district,\n",
    "#                      block=block,\n",
    "#                      layer_name='change_tree_cover_loss_raster',\n",
    "#                     #  layer_map_csv_path='../data/input/metadata/layer_mapping.csv',\n",
    "#                     #  layer_desc_csv_path='../data/input/metadata/layer_descriptions.csv',\n",
    "#                      #start_year='2021'\n",
    "#                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "71dc80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_raster_stac(state=state,\n",
    "#                      district=district,\n",
    "#                      block=block,\n",
    "#                      layer_name='change_cropping_reduction_raster',\n",
    "#                     #  layer_map_csv_path='../data/input/metadata/layer_mapping.csv',\n",
    "#                     #  layer_desc_csv_path='../data/input/metadata/layer_descriptions.csv',\n",
    "#                      #start_year='2021'\n",
    "#                      )\n",
    "\n",
    "# generate_raster_stac(state=state,\n",
    "#                      district=district,\n",
    "#                      block=block,\n",
    "#                      layer_name='change_urbanization_raster',\n",
    "#                     #  layer_map_csv_path='../data/input/metadata/layer_mapping.csv',\n",
    "#                     #  layer_desc_csv_path='../data/input/metadata/layer_descriptions.csv',\n",
    "#                      #start_year='2021'\n",
    "#                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "127852d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_raster_stac(state=state,\n",
    "#                      district=district,\n",
    "#                      block=block,\n",
    "#                      layer_name='change_tree_cover_loss_raster',\n",
    "#                     #  layer_map_csv_path='../data/input/metadata/layer_mapping.csv',\n",
    "#                     #  layer_desc_csv_path='../data/input/metadata/layer_descriptions.csv',\n",
    "#                      #start_year='2021'\n",
    "#                      )\n",
    "\n",
    "# generate_raster_stac(state=state,\n",
    "#                      district=district,\n",
    "#                      block=block,\n",
    "#                      layer_name='land_use_land_cover_raster',\n",
    "#                     #  layer_map_csv_path='../data/input/metadata/layer_mapping.csv',\n",
    "#                     #  layer_desc_csv_path='../data/input/metadata/layer_descriptions.csv',\n",
    "#                      start_year='2021'\n",
    "#                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b2755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
